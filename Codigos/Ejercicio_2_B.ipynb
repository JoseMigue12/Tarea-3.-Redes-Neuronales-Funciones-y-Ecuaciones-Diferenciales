{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd1050-862a-4439-a1d4-dd75d1d8318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class ODEsolver(Sequential):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "    \n",
    "    @property\n",
    "    def metrics(self): \n",
    "        return [self.loss_tracker]\n",
    "\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        batch_size = 100\n",
    "        x = tf.random.uniform((batch_size,1), minval=-5, maxval=5)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            #Compute the Loss Value\n",
    "            with tf.GradientTape() as tape2:\n",
    "                tape2.watch(x)\n",
    "                #y_pred = self(x, training=True)\n",
    "                \n",
    "                with tf.GradientTape() as tape3:\n",
    "                    tape3.watch(x)\n",
    "                    y_pred = self(x, training=True)\n",
    "                    \n",
    "                y_x=tape3.gradient(y_pred,x)\n",
    "            \n",
    "            \n",
    "            y_xx=tape2.gradient(y_x,x)\n",
    "            \n",
    "            \n",
    "            #dy = tape2.gradient(y_pred, x)\n",
    "            x_o = tf.zeros((batch_size,1))\n",
    "            y_o = self(x_o, training=True)\n",
    "            eq = y_xx + y_pred\n",
    "            ic = y_o - 1\n",
    "            loss = keras.losses.mean_squared_error(0., eq) + keras.losses.mean_squared_error(0.,ic)\n",
    "            \n",
    "        #Apply grads\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        #update metrics\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        #Return a dict mapping metric names to current value\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "model = ODEsolver()\n",
    "\n",
    "model.add(Dense(10, activation='tanh', input_shape=(1,)))\n",
    "model.add(Dense(10, activation='tanh', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(), metrics=['loss'])\n",
    "\n",
    "x=tf.linspace(-5,5,100)\n",
    "history = model.fit(x,epochs=1000,verbose=1)\n",
    "\n",
    "x_testv = tf.linspace(-5,5,100)\n",
    "a=model.predict(x_testv)\n",
    "\n",
    "x_1 =np.arange(-5,5, 0.005) \n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "plt.plot(x_testv,a, label='Solución de la Red Neuronal')\n",
    "\n",
    "plt.plot(x_1,(np.cos(x_1) - 0.5*(np.sin(x_1))), label='Gráfica de la función original', color='red')\n",
    "\n",
    "plt.title( \"y(t) = Cos(x) - 0.5 Sin(x)\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(which='both')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
